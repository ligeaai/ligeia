version: "3.8"
services:
  frontend:
    restart: unless-stopped
    build:
      context: .
      dockerfile: ./dockerfile/local/frontend/Dockerfile
    container_name: ligeiaai-frontend-1
    env_file:
      - .env
    volumes:
      - ./:/frontend:delegated
    ports:
      - "3000:3000"
    environment:
      - CHOKIDAR_USEPOLLING=true
    networks:
      - net
  django:
    restart: unless-stopped
    build:
      context: .
      dockerfile: ./dockerfile/local/django/Dockerfile
    command: /start
    container_name: ligeiaai-django-1
    env_file:
      - .env
    volumes:
      - .:/django
      # - static_volume:/django/staticfiles
      # - media_volume:/django/mediafiles
    environment:
      - CELERY_BROKER=redis://redis:6379/1
      - CELERY_BACKEND=redis://redis:6379/1
    depends_on:
      - redis
      - postgres
      - apache-kafka-broker1
      # - es
    ports:
      - "8000:8000"
    networks:
      - net
  couchserver:
    image: couchdb
    restart: always
    container_name: ligeiaai-couchserver-1
    ports:
      - "5984:5984"
    environment:
      - COUCHDB_USER=${COUCHDB_USER}
      - COUCHDB_PASSWORD=${COUCHDB_PASSWORD}
    volumes:
      - couch-data:/opt/couchdb/data
  # es:
  #   image: elasticsearch:8.4.2
  #   container_name: ligeiaai-es-1
  #   environment:
  #     - discovery.type=single-node
  #   ports:
  #     - "9200:9200"
  #   deploy:
  #     resources: 
  #       limits: 
  #         cpus: "0.20"  # Use at most 50% of one CPU core
  #         memory: 1GB
  postgres:
    restart: unless-stopped
    image: postgres:latest
    container_name: ligeiaai-postgres-1
    volumes:
      - postgres-data:/var/lib/postgresql/data/
    # env_file:
    #   - .env
    environment:
      - POSTGRES_USER=${PG_USER}
      - POSTGRES_PASSWORD=${PG_PASS}
      - POSTGRES_DB=${PG_DB}
    ports:
      - "5434:5432"
    networks:
      - net
  pgadmin:
    restart: on-failure
    image: dpage/pgadmin4:latest
    container_name: ligeiaai-pgadmin-1
    volumes:
      - pgadmin-data:/var/lib/pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PG_ADMIN_EMAIL}
      PGADMIN_DEFAULT_PASSWORD: ${PG_ADMIN_PASS}
    ports:
      - "5050:80"
    networks:
      - net
  redis:
    restart: on-failure
    image: redis:latest
    container_name: ligeiaai-redis-1
    volumes:
      - redis-data:/data
    ports:
      - "6379:6379"
    networks:
      - net
  redis-ts:
    restart: on-failure
    image: redislabs/redistimeseries:latest
    container_name: ligeiaai-redis-ts
    ports:
      - "6380:6380"
    networks:
      - net
  zookeeper:
    hostname: zookeeper
    container_name: zookeeper
    image: 'bitnami/zookeeper:latest'
    ports:
      - "2181:2181"
    environment:
      - ZOOKEEPER_CLIENT_PORT=2181
      - ZOOKEEPER_TICK_TIME=2000
      - ALLOW_ANONYMOUS_LOGIN=yes
    networks:
      - net
  apache-kafka-broker1:
    image: confluentinc/cp-enterprise-kafka:5.3.1
    hostname: broker
    container_name: ligeiaai-apache-kafka-broker-1
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: broker:29092
      CONFLUENT_METRICS_REPORTER_ZOOKEEPER_CONNECT: zookeeper:2181
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: "true"
      CONFLUENT_SUPPORT_CUSTOMER_ID: "anonymous"
      KAFKA_JMX_HOSTNAME: localhost
    networks:
      - net
  nifi:
    build:
      context: .
      dockerfile: ./dockerfile/local/datapipline/Nifi/Dockerfile
    restart: unless-stopped
    image: apache/nifi:latest
    ports:
      - "8080:8080"
    volumes:
      - ./backend/services/datapipline/pre-processing:/datapipline
    environment:
      NIFI_WEB_HTTP_PORT: 8080
      NIFI_CLUSTER_IS_NODE: 'true'
      NIFI_CLUSTER_NODE_PROTOCOL_PORT: 8082
      NIFI_ZK_CONNECT_STRING: "zookeeper:2181"
      NIFI_ELECTION_MAX_WAIT: "1 min"
      NIFI_ZK_ROOT_NODE: "/nifi"
      NIFI_SENSITIVE_PROPS_KEY: '12345678912345'
    depends_on:
      - apache-kafka-broker1
      - zookeeper
    networks:
      - net
  rabbitmq:
    image: rabbitmq:3-management
    hostname: localhost
    container_name: ligeiaai-rabbitmq
    ports:
      - '15672:15672'
      - '5672:5672'
    networks:
      - net
  mongodb-timescale:
    image: mongo:latest
    ports:
      - 27017:27017
    volumes:
      - mongodb-data:/data/db
    environment:
      TZ: 'Etc/UTC'
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: admin
    depends_on:
      - apache-kafka-broker1
      - zookeeper
    networks:
      - net
networks:
  net:
    driver: bridge
volumes:
  postgres-data: null
  pgadmin-data: null
  redis-data: null
  couch-data: null
  zookeeper_data: null
  broker_data: null
  connect_data: null
  cassandra_data: null
  mongodb-data: null
  # apache-spark:
  #   restart: unless-stopped
  #   build:
  #     context: .
  #     dockerfile: ./dockerfile/local/datapipline/Spark/Dockerfile
  #   image: gettyimages/spark:2.4.1-hadoop-3.0
  #   container_name: ligeiaai-apache-spark
  #   volumes:
  #     - ./:/app
  #   ports:
  #     - '4040:4040'
  #   depends_on:
  #     - apache-kafka-broker1
  #     - zookeeper
  #   networks:
  #     - net
  # apache-cassandra:
  #   container_name: ligeiaai-apache-cassandra
  #   hostname: 'cassandra'
  #   image: docker.io/bitnami/cassandra:4.0
  #   expose:
  #     - 7000
  #     - 9042
  #   ports:
  #     - '7000:7000'
  #     - '9042:9042'
  #   volumes:
  #     - 'cassandra_data:/bitnami'
  #   environment:
  #     - CASSANDRA_SEEDS=cassandra
  #     - CASSANDRA_DC=DC1
  #     - CASSANDRA_RACK=rack1
  #   networks:
  #     - net
  #   depends_on:
  #     - apache-kafka-broker1
  #     - zookeeper
  # control-center:
  #   image: confluentinc/cp-enterprise-control-center:5.3.1
  #   hostname: control-center
  #   container_name: ligeiaai-control-center
  #   depends_on:
  #     - zookeeper
  #     - apache-kafka-broker1
  #   ports:
  #     - "9021:9021"
  #   environment:
  #     CONTROL_CENTER_BOOTSTRAP_SERVERS: 'broker:29092'
  #     CONTROL_CENTER_ZOOKEEPER_CONNECT: 'zookeeper:2181'
  #     CONTROL_CENTER_CONNECT_CLUSTER: 'connect:8088'
  #     CONTROL_CENTER_REPLICATION_FACTOR: 1
  #     CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
  #     CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
  #     CONFLUENT_METRICS_TOPIC_REPLICATION: 1
  #     PORT: 9021
  #   networks:
  #     - net
  # connect:
  #   build:
  #     context: .
  #     dockerfile: ./dockerfile/dev/datapipelines/Dockerfile
  #   container_name: ligeiaai-connect
  #   hostname: connect
  #   ports:
  #     - "8088:8088"
  #   depends_on:
  #     - apache-kafka-broker1
  #   environment:
  #     CONNECT_BOOTSTRAP_SERVERS: broker:29092
  #     CONNECT_GROUP_ID: "connect-group"
  #     CONNECT_CONFIG_STORAGE_TOPIC: "connect-config-storage"
  #     CONNECT_OFFSET_STORAGE_TOPIC: "connect-offset-storage"
  #     CONNECT_STATUS_STORAGE_TOPIC: "connect-status-storage"
  #     CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
  #     CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.converters.ByteArrayConverter"
  #     CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
  #     CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
  #     CONNECT_PLUGIN_PATH: "/usr/share/confluent-hub-components"
  #     CONNECT_REST_ADVERTISED_HOST_NAME: "connect"
  #     CONNECT_REST_HOST_NAME: "connect"
  #     CONNECT_REST_PORT: "8088"
  #     CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
  #     CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
  #     CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
  #     CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
  #     CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-5.1.1.jar
  #     CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
  #     CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
  #   networks:
  #     - net
  # celery_worker:
  #   restart: on-failure
  #   build:
  #     context: .
  #     dockerfile: ./dockerfile/local/django/Dockerfile
  #   command: /start-celeryworker
  #   image: doccano_backend:prod
  #   volumes:
  #     - .:/django
  #   env_file:
  #     - .env
  #   depends_on:
  #     - redis
  #     - postgres
  #     - django
  #   networks:
  #     - net
  # flower:
  #   build:
  #     context: .
  #     dockerfile: ./dockerfile/local/django/Dockerfile
  #   command: /start-flower
  #   volumes:
  #     - .:/django
  #   env_file:
  #     - .env
  #   ports:
  #     - "5557:5555"
  #   depends_on:
  #     - redis
  #     - postgres
  #     - celery_worker
  #   networks:
  #     - net
